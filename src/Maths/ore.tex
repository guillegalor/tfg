\chapter{Introducción a extensiones de Ore}%
\label{chap:conceptos_básicos_sobre_extensiones_ore}
\section{Conceptos básicos sobre extensiones de Ore}
En esta sección introduciremos algunos conceptos básicos necesarios para continuar. Aunque las definiciones que realizamos a continuación se pueden hacer más generales, nosotros las haremos en función a lo que necesitaremos para la siguiente sección. Dicho esto, nuestro algoritmo trabajará sobre polinomios de Ore no conmutativos, con una única indeterminada \(x\), con coeficientes en un cuerpo cualquiera. Precisando, nuestros polinomios serán elementos de un anillo asociativo \(R = \F[x;\sigma]\), donde

\begin{itemize}
    \item \(\F\) es un cuerpo cualquiera.
    \item \(\sigma: \F \to \F\) es un automorfismo de cuerpos de orden finito digamos \(n\).
\end{itemize}

La construcción de \(R = \F[x;\sigma]\) sigue de la siguiente forma:
\begin{itemize}
    \item \(R\) es un \(\F\)-espacio vectorial a la izquierda sobre la base  \(\{x^n: n \geq 0\). Entonces, los elementos de  \(R\) son polinomios a la izquierda de la forma \(a_0 + a_1 x + \cdots + a_n x^n\) con \(a_i \in \F\).
    \item La suma de polimios es la usual.
    \item El producto de \(R\) está basado en las siguientes reglas: \(x^n x^m = x^{n+m}\), para \(m, n \in \mathbb{N}\), y \(xa = \sigma(a)x\) para  \(a \in \F\). Este producto se extiende recursivamente a \(R\).
\end{itemize}

El grado \(\deg (f)\) de un polinomio no nulo \(f \in R\), al igual que su coeficiente lider se definen de la manera usual, tal que
\[
f = \lc(f)x^{\deg(f)} + f_{\downarrow}, \text{ con } \deg(f_{\downarrow}) < \deg(f) \text{ y } \lc(f) \neq 0
.\]

Escribimos \(\deg(0) = -\infty\), con las convenciones usuales para este símbolo, y \(\lc(0) = 0\).

Es facil comprobar que, dados \(f, g \in R\):
\[
\deg(fg) = \deg(f) + \deg(g), \quad \lc(fg) = \lc(f)\sigma^{\deg(f)}(\lc(g))
.\]

Esto nos dice que \(R\) es un dominio de integridad no conmutativo.

El anillo \(R\) tiene algoritmos de división a la izquierda y derecha (veánse los algoritmos \ref{left_euclidean_div} y \ref{right_euclidean_div}).

\begin{algorithm}[H]
 \label{left_euclidean_div}
 \SetKwInput{KwIn}{Entrada}
 \SetKwInput{KwOut}{Salida}
 \SetKw{Initialization}{Inicialización:}
 \KwIn{\(f,g \in \F[x;\sigma] \text{ con } g \neq 0\)}
 \KwOut{\(q,r \in \F[x;\sigma] \text{ tales que } f = qg + r \text{ y } \deg(r) < \deg(g)\)}
 \Initialization{\(q:=0, r:=f\)} \\
 \While{\(\deg(g) \leq \deg(r)\)}{
  \(a = \lc(r)\sigma^{deg(r) - deg(g)}(\lc(g)^{-1})\) \\
  \(q := q + ax^{\deg(r) - \deg(g)}, r:= r - ax^{deg(r) - deg(g)}g\)
 }
 \caption{División Euclídea a la izquierda}
\end{algorithm}

\begin{algorithm}[H]
 \label{right_euclidean_div}
 \SetKwInput{KwIn}{Entrada}
 \SetKwInput{KwOut}{Salida}
 \SetKw{Initialization}{Inicialización:}
 \KwIn{\(f,g \in \F[x;\sigma] \text{ con } g \neq 0\)}
 \KwOut{\(q,r \in \F[x;\sigma] \text{ tales que } f = gq + r \text{ y } \deg(r) < \deg(g)\)}
 \Initialization{\(q:=0, r:=f\)} \\
 \While{\(\deg(g) \leq \deg(r)\)}{
  \(a = \sigma^{-deg(g)}(\lc(g)^{-1}\lc(r))\) \\
  \(q := q + ax^{\deg(r) - \deg(g)}, r:= r - gax^{deg(r) - deg(g)}\)
 }
 \caption{División Euclídea a la derecha}
\end{algorithm}

Mostramos a continuación una demostración que justifica estos algoritmos, cuya versión original puede encontrarse en~\cite[Th. 4.34]{bueso2003algorithmic}

\begin{theorem}
Sea \(\F\) un cuerpo finito de \(q\) elementos siendo \(q\) una potencia de un primo,  \(\sigma\) un autormorfismo de \(\F\) no nulo, y \(R = \F[x;\sigma]\) la extensión de Ore correspondiente. Entonces, dados \(f, g \in R\) exiten \(q, r \in R\) únicos tales que:
\begin{nlist}
    \item \(f = qg + r\).
    \item \(\deg(r) < \deg(g)\).
\end{nlist}

Bajo las mismas hipótesis, existen también \(q, r \in R\) únicos tales que:
\begin{nlist}
    \item \(f = gq + r\)
    \item \(\deg(r) < \deg(g)\).
\end{nlist}
\end{theorem}

\begin{proof}
Para abreviar digamos \(m = \deg(g), n = \deg(f)\). Veamos primero la prueba de la división a la izquierda. Si \(m > n\), entonces no tenemos nada que probar, pues tomando  \(q = 0, r = f\) se cumple el resultado. Por otro lado, si \(m \leq n\), sean \(f = \sum_{i=0}^{n} a_i x^i\) y \(g = \sum_{j=0}^{m} b_j x^j\), aplicaremos inducción sobre \(n\). Si \(n = 0\), entonces también \(m = 0\), así que  \(f = a_0, g = b_0\), y por tanto tomamos \(r = 0, q = a_0 b_0^{-1}\).

Por tanto, supongamos la afirmación cierta para todo \(f\) de grado menor que \(n\).  Sea \(a = a_n \sigma^{n-m}(b_m^{-1})\). Entonces es claro que
\[
\deg(ax^{n-m}g) = n,
\]
\[
\lc(ax^{n-m}g) = a_n
.\]
Por tanto tenemos que
\[
\deg(f - a x^{n-m}g) < n,
\]
y por tanto, la hipótesis de inducción nos dice que existen \(q'\) y \(r'\) compliendo que \(\deg(r') < \deg(g)\)  y
\[
f - a x^{n-m}g = q'g + r'
.\]

Sea
\[
q = a x^{n-m} + q'
,\]

entonces
\[
f = a x^{n-m}g + q'g + r' = qg + r'
.\]

Queda probar que \(q\) y \(r\) son únicos como tales. Supongamos que
\[
f = q_1g + r_1 = q_2g + r_2,
\]
con \(\deg(r_1), \deg(r_2) < \deg(g)\). Entonces, \((q_1 - q_2)g = r_2 - r_1\), y podemos afirmar entonces que
\[
\deg(q_1 - q_2) + \deg(g) = \deg((q_1-q_2)g)
\]
\[
= \deg(r_2-r_1) \leq \max(\deg(r_2), \deg(r_1)) < \deg(g)
.\]
Esto prueba que \(\deg(q_1-q_2) = -\infty\), demostrando que \(q_1 - q_2 = 0\) y que \(r_2 = r_1 = 0\) que termina la prueba de la primera parte.

La prueba de la división a la derecha es completamente análoga, tomando \(a = \sigma^{-m}(a_{n}b_{m}^{-1})\), y utilizando que \(\deg(f - gax^{n-m}) < n\).

\end{proof}

Los polinomios \(r\) y \(q\) obtenidos como salida del algoritmo \ref{left_euclidean_div} los llamaremos \textit{resto a la izquierda} y  \textit{cociente a la izquierda}, respectivamente, de la división a la izquierda de \(f\) por \(g\). Utilizaremos la notación \(r = \operatorname{lrem}(f,g)\) y \(q = \operatorname{lquo}(f,g)\). Asumimos convenciones y notaciones análogas para el algoritmo de división a la derecha.

Como consecuencia del algoritmo de división a la izquierda, dado un ideal a la izquierda \(I\) de \(R\), y cualquier polinomio no nulo  \(f \in I\) de grado mínimo, obtenemos que  \(f\) es un generador de  \(I\). Notaremos en este caso \(I = Rf\). Análogamente, cualquier ideal a la derecha de \(R\) es principal.  Por tanto \(R\) es un dominio de ideales principales no conmutativo.

Dados \(f,g \in R\), \(Rf \subset Rg\) implica que \(g\) es un \textit{divisor a la derecha} de \(f\), simbólicamente \(g|_{r} f\), o que \(f\) es \textit{múltiplo a la izquierda} de \(g\).

Por ser \(R\) un DIP sabemos que \(Rf + Rg = Rd\) para algún \(d \in R\), y es inmediato comprobar que \(d |_r f\) y  \(d |_r g\). Además, si tenemos \(d'\) con \(d' |_r f\), \(d' |_r g\), entonces \(Rf + Rg \subset Rd'\), luego \(Rd \subset Rd'\) y por tanto  \(d |_r d'\). En este caso diremos que \(d\) es un máximo común divisor a la derecha de \(f\) y \(g\), estando unívocamente determinado salvo múltiplicación a la izquierda por una unidad de \(R\). Utilizaremos la notación \(d = {(f,g)}_r\). Además de aquí obtenemos directamente la \textbf{identidad de Bezout}.

Similarmente  \(Rf \cap Rg = Rm\) si y solo si \(m\) es un mínimo común múltiplo a la izquierda de \(f\) y \(g\), notado por \(m = {[f,g]}_l\). Este también es único salvo multiplicación a la izquierda por una unidad de \(R\).

Tanto \((f,g)_r\) como \([f,g]_l\) se pueden calcular utilizando el Algoritmo Extendido de Euclides a la izquierda. La versión a la derecha de estas definiciones y propiedades puede establecerse análogamente. Más adelante utilizaremos el Algoritmo Extendido de Euclides a la derecha, que nos proporciona los coeficientes de Bezout en cada etapa del algoritmo, por esto es la que demostramos a continuación y describimos explícitamente en el algoritmo \(\ref{alg:right_ext_euc_alg}\).

\begin{algorithm}[H]
 \label{alg:right_ext_euc_alg}
 \SetKwInput{KwIn}{Entrada}
 \SetKwInput{KwOut}{Salida}
 \SetKw{Initialization}{Inicialización:}
 \KwIn{\(f,g \in \F[x;\sigma] \text{ con } f \neq 0,\ g \neq 0\)}
 \KwOut{\(\{u_i, v_i, r_i\}_{i = 0, \dots, h, h+1} \text{ tales que } r_i = fu_i + gv_i \text{ para todo  } i, r_h = (f,g)_l, \text{ y } u_{h+1}f = [f,g]_r.\)}
 \Initialization{\\
 \(r_0 \leftarrow f, r_1 \leftarrow g\) \\
 \(u_0 \leftarrow 1, u_1 \leftarrow 0\) \\
 \(v_0 \leftarrow 0, v_1 \leftarrow 1\) \\
 \(q \leftarrow 0, rem \leftarrow 0\) \\
 \(i \leftarrow 1\) \\
 }
 \While{\(r_i \neq 0\)}{
  \(q,\ rem \leftarrow \operatorname{rquot-rem}(r_{i-1}, r_i)\) \\
  \(r_{i+1} \leftarrow rem\) \\
  \(u_{i+1} \leftarrow u_{i-1} - u_i q\) \\
  \(v_{i+1} \leftarrow v_{i-1} - v_{i} q\)
  \(i \leftarrow i +1\) \\
 \Return{\(\{u_i, v_i, r_i\}_{i = 0, \dots, h, h+1}\)}
 }
 \caption{Algoritmo extendido de Euclides a la derecha}
\end{algorithm}

Antes de pasar con la demostración del algoritmo probaremos un resultado que nos será necesario para esta.

\begin{proposition}
    Sean \(u,v,f,g \in R\) tales que \(fu = gv\). Entonces,  \({(u,v)}_{l} = 1 \implies {[f,g]}_r = fu\).
\end{proposition}

\begin{proof}
    La identidad de Bezout nos proporciona coeficientes \(a, b\) tales que \(1 = ua + vb\). Entonces, dado \(h \in fR \cap gR\), veamos que \(fu |_{l} h\). Sean \(u', v'\) tales que \(h = fu' = gv'\),
    \[
    \begin{aligned}
        fu' &= fu'ua + fu'vb \\
        gv' &= gv'ua + gv'vb
    \end{aligned}
    .\]
\end{proof}

\begin{theorem}[\cite{algI}]
    El algoritmo~\ref{alg:right_ext_euc_alg} es correcto.
\end{theorem}
\begin{proof}
    En primer lugar, vemos que siempre que \(r_i \neq 0\) se tiene que \(\deg(r_{i+1}) < \deg(r_i)\), por tanto existe  \(h \geq 1\) tal que \(r_h \neq 0\) pero \(r_{h+1} = 0\).

Para \(i \leq h\) tenemos que \(r_i \neq 0\), y por tanto podemos utilizar la división a la derecha de \(r_{i-1}\) entre \(r_i\) para obtener

\[
r_{i-1} = r_i q_{i+1} + r_{i+1}
.\]

De aquí obtenemos que los divisores a la izquierda comunes de \(r_{i-1}\) y de \(r_i\) coinciden con los divisores a la izquierda comunes de  \(r_i\) y de  \(r_{i+1}\). Luego
\[
r_h = (0, r_h)_l = (r_{h+1}, r_h)_l = (r_h, r_{h-1-})_l = \cdots = (r_1, r_0)_l = (g,f)_l
.\]

Ahora vamos a definir \(u_i, v_i \in R\) con \(i = 0,1, \dots, h, h+1\). En primer lugar, tomamos
\[
u_0 = 1,\ v_0 = 0,\ u_1 = 0,\ v_1 = 1.
.\]
Una vez dados \(u_{i-1}, v_{i-1}, u_i, v_i\) para \(1 \leq i \leq h\) definimos
\[
u_{i+1} = u_{i-1} - u_iq_{i+1}, \quad
v_{i+1} = v_{i-1} - v_iq_{i+1}
.\]

Aplicaremos un argumento por inducción para comprobar que \(r_i = fu_i + gv_i\). Es inmediato comprobar que para \(i = 0,1\) se cumple, así que supongamos que se cumple para \(i-1,\ i\) y veamos que se cumple para \(i+1\). En efecto
\[
f u_{i+1} + g v_{i+1j} = f(u_{i-1} - u_iq_{i+1}) + g(v_{i-1} - v_iq_{i+1}) =
\]
\[
f u_{i-1} + g v_{i-1} - (f u_i + g v_i)q_{i+1} = r_{i-1} - r_iq_{i+1} = r_{i+1}
.\]

TODO-*-*-*
Veamos para concluir que \(u_{h+1}f = [f,g]_r\). Observemos que \(0 = r_{h+1} = fu_{h+1} + gv_{h+1}\), luego \(fu_{h+1} = -gv_{h+1}\) es un múltiplo a la derecha común de \(f\) y \(g\). Para terminar y ver que \(f u_{h+1} = [f,g]_r\) demostremos primero que
\[-u_{i+1}v_i + u_iv_{i+1} = 1\quad \forall 0 \leq i \leq h.\]
Esta igualdad es clara para \(i = 0\). Si \(1 \leq i \leq h\), supuesta la igualdad para \(i-1\), tenemos
\[
-u_{i+1}v_i + u_iv_{i+1} = -(u_{i-1} - u_iq_{i+1})v_i + u_i(v_{i-1} - v_iq_{i+1}) =
.\]
\end{proof}
-*-*-*-*

Veamos ahora un lema que nos será útil posteriormente.

\begin{lemma}
\label{lem:reea}
    Sean \(f, g \in \F[x; \sigma] \) y \(  {\{u_{i}, v_{i}, r_{i}\}}_i = 0, \ldots, h\) los coeficientes obtenido al aplicar el Algoritmo Extendido de Euclides a la derecha a \(f\) y \(g\). Notemos \(R_{0} =
    \begin{pmatrix}
    u_0 & v_0 \\
    u_1 & v_1
    \end{pmatrix},\)
    \(Q_i =
    \begin{pmatrix}
        0 & 1 \\
        1 & -q_i
    \end{pmatrix}
    \)
    y \(R_i =  R_0 Q_1 \cdots Q_i\) para cualquier \(i = 0, \ldots, h\). Por tanto, para todo \(i = 0, \ldots, h\) se cumplen las siguientes afirmaciones:

    \begin{enumerate}[label=\roman*)]
        \item \((fg)R_i = (r_{i-1} r_i)\).
        \item \(R_i =
            \begin{pmatrix}
            u_i & u_{i+1} \\
            v_{i} & v_{i+1}
            \end{pmatrix}\).
        \item \(f u_i + g v_i = r_i\).
        \item \(R_i\) tiene inverso a izquierda y derecha.
        \item \((u_i, v_i)_r = 1\).
        \item \(\deg f = \deg r_{i-1} + \deg v_{i}\).

    \end{enumerate}
\end{lemma}
\begin{proof}
    TODO
\end{proof}

Ahora, con el objetivo de poder definir la evaluación de nuestro polinomios, dado \(j \geq 0\), definimos la \textit{norma j-ésima} para cualquier \(\gamma \in \F\) de forma recursiva como sigue:
\[
N_0(\gamma) = 1
\]
\[
N_{j+1}(\gamma) = \gamma \sigma(N_{j}(\gamma)) = \gamma \sigma(\gamma)\dots\sigma^{j}(\gamma)
.\]
La noción de norma j-ésima admite también una versión para índices negativos dada por
\[
N_{-j-1}(\gamma) = \gamma \sigma^{-1}(N_{-j}(\gamma)) =  \gamma \sigma^{-1}(\gamma) \cdots \sigma^{-j}(\gamma)
.\]
La \textit{evaluación la izquierda} de un polinomio no conmutativo \(f \in R\) en un \(a \in \F\) se define como el resto de la división a la izquierda de \(f\) por  \(x - a\), y de forma similar para la  \textit{evaluación a la derecha}. Estas evaluaciones nos permiten hablar de raíces a izquierda y derecha de estos polinomios.

\begin{lemma}
\label{lem:eval}
    Sea \(\gamma \in \F\) y  \(f = \sum_{i=0}^n f_ix^i \in R\). Entonces:
    \begin{nlist}
    \item El resto de la división a la izquerda de \(f\) por  \(x - \gamma\) es  \(\sum_{i=0}^{n} f_i N_i(\gamma)\).
    \item El resto de la división a la derecha de \(f\) por  \(x - \gamma\) es  \(\sum_{i=0}^{n}\sigma^{-i}(f_i)N_{-i}(\gamma)\).
    \item \(N_j(\sigma^k(\gamma)) = \sigma^k(N_j(\gamma))\) para todo \(i,k\).
    \end{nlist}
\end{lemma}
\begin{proof}
    Para demostrar \textit{i)} observamos primero un caso especial de este resultado:
\begin{equation}
\label{norm_proof}
    x^j - N_j(\gamma) \in R(x-\gamma)\ \forall j \geq 0.
\end{equation}
    Es evidente que el resultado es cierto para \(j = 0\), asi que procedemos por inducción sobre \(j\). Supongamos el resultado cierto para \(j\), entonces
\[
\begin{aligned}
x^{j+1} - N_{j+1}(\gamma) &= x^{j+1} - \sigma(N_j(\gamma))\gamma \\
&= x^{j+1} +  \sigma(N_j(\gamma))(x-\gamma) - \sigma(N_j(\gamma))x \\
&= x^{j+1} +  \sigma(N_j(\gamma))(x-\gamma) - xN_j(\gamma) \\
&= \sigma(N_j(\gamma))(x-\gamma) + x(x^{j} - N_j(\gamma)) \in R(x-\gamma)
\end{aligned}
.\]
Utilizando (\ref{norm_proof}) tenemos entonces que
\[
f - \sum_{i=0}^n f_i N_i(\gamma) = \sum_{i=0}^n f_i(x^i - N_i(\gamma)) \in R(x - \gamma)
\]
y, por la unicidad del resto de la división euclídea tenemos que \(r = \sum_{i=0}^n f_i N_i(\gamma)\).

Para la siguiente afirmación procedemos de forma similar. Veamos en primer lugar que
\begin{equation}
\label{right_norm_proof}
    x^j - N_{-j}(\gamma) \in (x-\gamma)R\ \forall j \geq 0.
\end{equation}

De nuevo, es obvio para \(j = 0\), por tanto procedemos por inducción supuesto cierto para \(j\).
\[
\begin{aligned}
x^{j+1} - N_{-j-1}(\gamma) &= x^{j+1} - \gamma\sigma^{-1}(N_j(\gamma))  \\
&= x^{j+1} +  (x-\gamma)\sigma^{-1}(N_{-j}(\gamma)) - x\sigma^{-1}(N_{-j}(\gamma)) \\
&= x^{j+1} + (x-\gamma)\sigma^{-1}(N_{-j}(\gamma)) - N_{-j}(\gamma)x \\
&= (x-\gamma)\sigma^{-1}(N_{-j}(\gamma)) + (x^{j} - N_{-j}(\gamma))x \in (x-\gamma)R
\end{aligned}
.\]
Así, usando (\ref{right_norm_proof}) vemos que
\[
f - \sum_{i=0}^n \sigma^{-i}(f_i) N_{-i}(\gamma) = \sum_{i=0}^n x^i\sigma^{-i}(f_i) - N_{-i}(\gamma)\sigma^{-i}(f_i)
\]
\[
= \sum_{i=0}^n (x^i - N_{-i}(\gamma))\sigma^{-i}(f_i) \in (x - \gamma)R
.\]
Así que por la unicidad del resto queda probado \textit{ii)}.

Para probar \textit{iii)},
    \[
    N_j(\sigma^k(\gamma)) = \sigma^k(\gamma)\sigma^{k+1}(\gamma)\cdots\sigma^{k+j-1}(\gamma)
\]
\[
    = \sigma^k(\gamma \sigma(\gamma)\dots\sigma^{j-1}(\gamma)) = \sigma^k(N_j(\gamma))
    .\]
\end{proof}
